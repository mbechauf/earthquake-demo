{"paragraphs":[{"text":"%sh\n\ncd /tmp\nif [ -e /tmp/GEM-GHEC-v1.txt ]\nthen\n    rm -f /tmp/GEM-GHEC-v1.txt\nfi\nif [ -e /tmp/isc-gem-cat.zip ]\nthen\n    rm -f /tmp/isc-gem-cat.zip\nfi\nif [ -e /tmp/isc-gem-cat.csv ]\nthen\n    rm -f /tmp/isc-gem-cat.csv\nfi \nif [ -e /tmp/isc-gem-cat.kmz ]\nthen\n    rm -f /tmp/isc-gem-cat.kmz\nfi \n\nif hadoop fs -stat /tmp/isc-gem-cat.csv\nthen\n   hadoop fs -rm  /tmp/isc-gem-cat.csv\nfi\nif hadoop fs -stat /tmp/GEM-GHEC-v1.txt\nthen\n   hadoop fs -rm  /tmp/GEM-GHEC-v1.txt\nfi\n\nwget https://s3.amazonaws.com/bcgta-earthquake-data/GEM-GHEC-v1.txt\nwget https://s3.amazonaws.com/bcgta-earthquake-data/isc-gem-cat.zip\n\nunzip isc-gem-cat.zip isc-gem-cat.csv\nhadoop fs -put GEM-GHEC-v1.txt /tmp\nhadoop fs -put isc-gem-cat.csv /tmp\necho \"done\"\n\n","user":"anonymous","dateUpdated":"2018-04-07T02:56:30+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523034761468_-647018656","id":"20180406-171241_777364924","dateCreated":"2018-04-06T17:12:41+0000","dateStarted":"2018-04-07T02:56:30+0000","dateFinished":"2018-04-07T02:57:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:17043"},{"title":"Make a Spark RDD and a schema to go with it. Perform some more clean up steps of the data.","text":"\n//create RDD\nval historicalData = sc.textFile(\"/tmp/GEM-GHEC-v1.txt\")\n\n//define the schema\nval globalInstrumentalCatalogData = sc.textFile(\"/tmp/isc-gem-cat.csv\")\ncase class EarthQuake(\nid: String,\ndate: String,\nlat: Double,\nlon: Double,\ndepth: Double,\nmag: Double,\nmunc: Double\n)\n\n//clean up the records. Delimit by tabs and peel out the year/month\n//remove unwanted data entries\nval historical = historicalData.filter(s =>\n!s.startsWith(\"#\") && !s.startsWith(\"En\\tSource\")\n).map{s=>\n//make a function to peel out the year\ndef get(s:String) = {\nif (s==\"\") {\n\"00\"\n} else {\ns\n}\n}\nval r = s.split(\"\\t\")\nval year = r(2) // year\nif (r(2) != \"\") {\nval month = r(2)\n} else {\n//...and peel out the month\nval month = \"00\"\n}\n//format the date\nval date = r(2) + \"-\" + get(r(3)) + \"-\" + get(r(4)) + \" \" + get(r(5)) + \":\" + get(r(6)) + \":\" + get(r(7)) + \".00\"\n\n//extract interesting earthquake data:  id, date, depth, magnitude, \"uncorrected\" magnitude\nEarthQuake(\nr(0).toString, // id\ndate,\nget(r(9)).toDouble,\nget(r(10)).toDouble,\nget(r(14)).toDouble, // depth\nget(r(17)).toDouble, // mag\nget(r(18)).toDouble // mag unc\n\n)\n}\n\nval earthQuake = globalInstrumentalCatalogData.filter(!_.startsWith(\"#\")).map{s=>\nval r = s.split(\",\")\nEarthQuake(\nr(23).trim,\nr(0).trim,\nr(1).toDouble,\nr(2).toDouble,\nr(7).toDouble,\nr(10).toDouble,\nr(11).toDouble\n)\n}.union(historical).toDF   //make a dataframe\n//make a table to query\nearthQuake.registerTempTable(\"eq\")","user":"anonymous","dateUpdated":"2018-04-07T02:56:30+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523066956735_253426460","id":"20180407-020916_542540771","dateCreated":"2018-04-07T02:09:16+0000","dateStarted":"2018-04-07T02:56:30+0000","dateFinished":"2018-04-07T02:56:35+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17044"},{"title":"Display the average magnitude, maximum magnitude, and minimum magnitude for all the earthquakes per year.","text":"%sql select substring(date, 0, 4) as dt, avg(mag) as avg, max(mag) as max, min(mag) as min from eq group by substring(date, 0, 4) order by dt\n\n","user":"anonymous","dateUpdated":"2018-04-07T02:56:30+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"scatterChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523034865633_157060572","id":"20180406-171425_1279942251","dateCreated":"2018-04-06T17:14:25+0000","dateStarted":"2018-04-07T02:56:30+0000","dateFinished":"2018-04-07T02:56:38+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17045"},{"title":"Make another table with the average depth for all earthquakes that year.","text":"%sql select substring(date, 0, 4) as dt, avg(depth) as depth from eq group by substring(date, 0, 4) order by dt","user":"anonymous","dateUpdated":"2018-04-07T02:56:36+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"scatterChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067064097_-436258108","id":"20180407-021104_62089526","dateCreated":"2018-04-07T02:11:04+0000","dateStarted":"2018-04-07T02:56:36+0000","dateFinished":"2018-04-07T02:56:41+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17046"},{"title":"Plot the number of recorded earthquakes per year","text":"%sql \nselect substring(date, 0, 4) as dt, count(*) as cnt \nfrom eq \nwhere substring(date, 0, 4) > ${dt=1800}\ngroup by substring(date, 0, 4) \norder by dt","user":"anonymous","dateUpdated":"2018-04-07T02:56:39+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"scatterChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql","title":true},"settings":{"params":{"dt":"1800"},"forms":{"dt":{"name":"dt","defaultValue":"1800","hidden":false,"$$hashKey":"object:17694"}}},"apps":[],"jobName":"paragraph_1523067096479_102051576","id":"20180407-021136_354545145","dateCreated":"2018-04-07T02:11:36+0000","dateStarted":"2018-04-07T02:56:39+0000","dateFinished":"2018-04-07T02:56:43+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17047"},{"title":"Now lets run a machine learning algorithm to predict … the probabilty of a magnitude 6.0 or higher.","text":"import org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.ml.feature.Bucketizer\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.feature.PCA\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.feature.Binarizer","user":"anonymous","dateUpdated":"2018-04-07T02:56:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067234154_-218859132","id":"20180407-021354_1451834076","dateCreated":"2018-04-07T02:13:54+0000","dateStarted":"2018-04-07T02:56:41+0000","dateFinished":"2018-04-07T02:56:45+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17048"},{"title":"Let's look at a row of the earthquake data and create a dataframe (with year instead of full date).","text":"earthQuake.show(1)\nval eq2 = earthQuake.selectExpr(\"id\", \"substr(date,1,4) as year\", \"lat\", \"lon\", \"depth\", \"mag\", \"munc\").toDF","user":"anonymous","dateUpdated":"2018-04-07T02:56:43+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067302783_1200387616","id":"20180407-021502_1155789653","dateCreated":"2018-04-07T02:15:02+0000","dateStarted":"2018-04-07T02:56:43+0000","dateFinished":"2018-04-07T02:56:47+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17049"},{"title":"Some type casts","text":"val df = eq2.select(eq2(\"id\").cast(\"double\"),\neq2(\"year\").cast(\"double\"),\neq2(\"lat\").cast(\"double\"),\neq2(\"lon\").cast(\"double\"),\neq2(\"depth\").cast(\"double\"),\neq2(\"mag\").cast(\"double\"),\neq2(\"munc\").cast(\"double\"))\n\ndf.show(3)\n\n","user":"anonymous","dateUpdated":"2018-04-07T02:56:46+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067322842_-2090522968","id":"20180407-021522_90407659","dateCreated":"2018-04-07T02:15:22+0000","dateStarted":"2018-04-07T02:56:46+0000","dateFinished":"2018-04-07T02:56:49+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17050"},{"title":"Now create training and testing data sets. (60% for training and 40% for testing)","text":"val Array(training, testing) = df.randomSplit(Array(0.6, 0.4))","user":"anonymous","dateUpdated":"2018-04-07T02:56:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523069371592_1468994007","id":"20180407-024931_201577377","dateCreated":"2018-04-07T02:49:31+0000","dateStarted":"2018-04-07T02:56:47+0000","dateFinished":"2018-04-07T02:56:49+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17051"},{"title":"We'll use a VectorAssembler to combine many features into one feature column (logistic regression likes that)","text":"import org.apache.spark.ml.feature.VectorAssembler\nval assembler = new VectorAssembler()\n  .setInputCols(Array(\"id\", \"year\", \"lat\", \"lon\", \"depth\", \"mag\", \"munc\"))\n  .setOutputCol(\"featureSet\")","user":"anonymous","dateUpdated":"2018-04-07T02:56:49+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067363546_-768464451","id":"20180407-021603_205356892","dateCreated":"2018-04-07T02:16:03+0000","dateStarted":"2018-04-07T02:56:49+0000","dateFinished":"2018-04-07T02:56:50+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17052"},{"title":"Set the binary threshold to Richter scale Magnitude of 6.0","text":"val binaryClassifier = new Binarizer().setInputCol(\"mag\").setOutputCol(\"binaryLabel\").setThreshold(6.0)","user":"anonymous","dateUpdated":"2018-04-07T02:56:49+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067383674_1751671493","id":"20180407-021623_2126084382","dateCreated":"2018-04-07T02:16:23+0000","dateStarted":"2018-04-07T02:56:49+0000","dateFinished":"2018-04-07T02:56:51+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17053"},{"title":"Create a logistic regression model and set some parameters","text":"val lr = new LogisticRegression().setMaxIter(20).setRegParam(0.2).setElasticNetParam(0.8).setLabelCol(\"binaryLabel\").setFeaturesCol(\"featureSet\")","user":"anonymous","dateUpdated":"2018-04-07T02:56:50+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067398136_-1962142718","id":"20180407-021638_446259416","dateCreated":"2018-04-07T02:16:38+0000","dateStarted":"2018-04-07T02:56:50+0000","dateFinished":"2018-04-07T02:56:52+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17054"},{"title":"Chain everything together with a Spark Pipeline (great way to organize steps)","text":"val pipeline = new Pipeline()\n  .setStages(Array(assembler, binaryClassifier, lr))","user":"anonymous","dateUpdated":"2018-04-07T02:56:51+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067413268_707275799","id":"20180407-021653_34063029","dateCreated":"2018-04-07T02:16:53+0000","dateStarted":"2018-04-07T02:56:51+0000","dateFinished":"2018-04-07T02:56:53+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17055"},{"title":"Train the model","text":"val model = pipeline.fit(training)","user":"anonymous","dateUpdated":"2018-04-07T02:56:52+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067427123_105913268","id":"20180407-021707_1684652937","dateCreated":"2018-04-07T02:17:07+0000","dateStarted":"2018-04-07T02:56:52+0000","dateFinished":"2018-04-07T02:56:55+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17056"},{"title":"Make predictions","text":"val prediction = model.transform(testing)","user":"anonymous","dateUpdated":"2018-04-07T02:56:53+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"title":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067438215_-410389107","id":"20180407-021718_1069342043","dateCreated":"2018-04-07T02:17:18+0000","dateStarted":"2018-04-07T02:56:53+0000","dateFinished":"2018-04-07T02:56:56+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17057"},{"title":"Display the results","text":"prediction.select(\"prediction\", \"binaryLabel\", \"mag\").show(10)","user":"anonymous","dateUpdated":"2018-04-07T02:57:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"title":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067455047_495156562","id":"20180407-021735_1271720828","dateCreated":"2018-04-07T02:17:35+0000","dateStarted":"2018-04-07T02:57:32+0000","dateFinished":"2018-04-07T02:57:33+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17058"},{"title":"How well did we do? We need to quantify the error.","text":"val matches = udf((A : Int, B: Int) => {\n    if (A+B == 1) 0\n    else 1\n})\n\nval total = prediction.count\nval rightWrong = prediction.withColumn(\"matches\", matches($\"prediction\", $\"binaryLabel\")).groupBy(\"matches\").count.toDF\nrightWrong.registerTempTable(\"rightWrong\")\nrightWrong.show","user":"anonymous","dateUpdated":"2018-04-07T02:56:56+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"title":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067467242_-749506130","id":"20180407-021747_1811636731","dateCreated":"2018-04-07T02:17:47+0000","dateStarted":"2018-04-07T02:56:56+0000","dateFinished":"2018-04-07T02:57:02+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17059"},{"title":"Accuracy = Correct / Total","text":"rightWrong.where($\"matches\"===1).select(rightWrong(\"count\") / total* 100 ).show","user":"anonymous","dateUpdated":"2018-04-07T02:56:59+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067486848_1241615400","id":"20180407-021806_1469423512","dateCreated":"2018-04-07T02:18:06+0000","dateStarted":"2018-04-07T02:56:59+0000","dateFinished":"2018-04-07T02:57:04+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17060"},{"title":"Not too bad an accuracy !","user":"anonymous","dateUpdated":"2018-04-07T02:56:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523067500681_647178350","id":"20180407-021820_463237969","dateCreated":"2018-04-07T02:18:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17061"}],"name":"Earthquake Data","id":"2DCKUQ26X","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}